{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca31b75-85be-4735-b11f-ac21bf0346f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR DEENA\n",
    "!pip3 install sagemaker\n",
    "!pip3 install boto3\n",
    "!pip3 install json\n",
    "!pip3 install transformer\n",
    "\n",
    "#need to request more quotas for \"ml.m5.xlarge for transform job usage\", \"ml.m5.xlarge for endpoint usage\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ac3958-4d4d-4a16-81e3-770ec766f5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65e2b18b-b38d-446f-b91f-f1a078e5d48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2024-01-10-17-43-22-630\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-inference-2024-01-10-17-43-23-210\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-inference-2024-01-10-17-43-23-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'Person_Name',\n",
       "  'score': 0.8258283734321594,\n",
       "  'index': 4,\n",
       "  'word': 'Sarah',\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'entity': 'Person_Name',\n",
       "  'score': 0.8314036130905151,\n",
       "  'index': 5,\n",
       "  'word': 'Jessica',\n",
       "  'start': 17,\n",
       "  'end': 24},\n",
       " {'entity': 'Person_Name',\n",
       "  'score': 0.849219560623169,\n",
       "  'index': 6,\n",
       "  'word': 'Parker',\n",
       "  'start': 25,\n",
       "  'end': 31},\n",
       " {'entity': 'Person_Name',\n",
       "  'score': 0.7736506462097168,\n",
       "  'index': 12,\n",
       "  'word': 'Jessica',\n",
       "  'start': 52,\n",
       "  'end': 59},\n",
       " {'entity': 'location',\n",
       "  'score': 0.7681230306625366,\n",
       "  'index': 17,\n",
       "  'word': 'College',\n",
       "  'start': 74,\n",
       "  'end': 81},\n",
       " {'entity': 'location',\n",
       "  'score': 0.6825906038284302,\n",
       "  'index': 18,\n",
       "  'word': 'Park',\n",
       "  'start': 82,\n",
       "  'end': 86}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hugging Face Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID': 'mdarhri00/named-entity-recognition',\n",
    "    'HF_TASK': 'token-classification'\n",
    "}\n",
    "\n",
    "# Create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.26.0',\n",
    "    pytorch_version='1.13.1',\n",
    "    py_version='py39',\n",
    "    env=hub,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,  # Number of instances\n",
    "    instance_type='ml.m5.xlarge'  # EC2 instance type\n",
    ")\n",
    "\n",
    "# Make a prediction using the deployed model\n",
    "predictor.predict({\n",
    "    \"inputs\": \"My name is Sarah Jessica Parker but you can call me Jessica and I live in College Park\",\n",
    "})\n",
    "\n",
    "#choppy results so could make a code that if entity is the same for two things with neighboring indexes, could that as one location or person name\n",
    "\n",
    "#NOTE for error regarding (ResourceLimitExceeded) you have to go to SageMaker and search \"increase quota\" then search \"ml.m5.xlarge\" and request more quotas each time. Then re-run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1c3ee8-5f0a-4976-acb1-c3cf7a7e92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-pytorch-inference-2024-01-10-17-43-22-630\n",
      "huggingface-pytorch-inference-2024-01-10-15-15-15-481\n",
      "huggingface-pytorch-inference-2024-01-10-15-14-37-014\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.list_models(\n",
    ")\n",
    "\n",
    "for model in response['Models']:\n",
    "    print(model['ModelName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd3d9bc-b86d-46e7-925a-7053967ca36c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: huggingface-pytorch-inference-2024-01-10-18-12-51-287\n"
     ]
    },
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTransformJob operation: The account-level service limit 'ml.m5.xlarge for transform job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please use AWS Service Quotas to request an increase for this quota. If AWS Service Quotas is not available, contact AWS support to request an increase for this quota.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 30\u001b[0m\n\u001b[1;32m     22\u001b[0m transformer \u001b[38;5;241m=\u001b[39m Transformer(\n\u001b[1;32m     23\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m     24\u001b[0m     instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m     instance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml.m5.xlarge\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingleRecord\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Start the batch transform job\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_s3_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mS3Prefix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$[0,5]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Wait for the job to finish\u001b[39;00m\n\u001b[1;32m     39\u001b[0m transformer\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/transformer.py:302\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config, wait, logs)\u001b[0m\n\u001b[1;32m    292\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m    294\u001b[0m batch_data_capture_config \u001b[38;5;241m=\u001b[39m resolve_class_attribute_from_config(\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     batch_data_capture_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     sagemaker_session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session,\n\u001b[1;32m    300\u001b[0m )\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_transform_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TransformJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_client_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_data_capture_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_transform_job\u001b[38;5;241m.\u001b[39mwait(logs\u001b[38;5;241m=\u001b[39mlogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/transformer.py:635\u001b[0m, in \u001b[0;36m_TransformJob.start_new\u001b[0;34m(cls, transformer, data, data_type, content_type, compression_type, split_type, input_filter, output_filter, join_source, experiment_config, model_client_config, batch_data_capture_config)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Placeholder docstring\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m transform_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_transform_args(\n\u001b[1;32m    621\u001b[0m     transformer,\n\u001b[1;32m    622\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m     batch_data_capture_config,\n\u001b[1;32m    633\u001b[0m )\n\u001b[0;32m--> 635\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransform_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(transformer\u001b[38;5;241m.\u001b[39msagemaker_session, transformer\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3562\u001b[0m, in \u001b[0;36mSession.transform\u001b[0;34m(self, job_name, model_name, strategy, max_concurrent_transforms, max_payload, input_config, output_config, resource_config, experiment_config, env, tags, data_processing, model_client_config, batch_data_capture_config)\u001b[0m\n\u001b[1;32m   3559\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransform request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_transform_job(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n\u001b[0;32m-> 3562\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6152\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6137\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6140\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6141\u001b[0m ):\n\u001b[1;32m   6142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6143\u001b[0m \n\u001b[1;32m   6144\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6150\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6151\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3560\u001b[0m, in \u001b[0;36mSession.transform.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   3558\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating transform job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m   3559\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransform request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m-> 3560\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_transform_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTransformJob operation: The account-level service limit 'ml.m5.xlarge for transform job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please use AWS Service Quotas to request an increase for this quota. If AWS Service Quotas is not available, contact AWS support to request an increase for this quota."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "#NOTE INCREASE ml.m5.xlarge for transform job usage within Amazon in quotas\n",
    "\n",
    "# Create a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Define the model name (replace with your deployed model name)\n",
    "model_name = 'huggingface-pytorch-inference-2024-01-10-15-15-15-481'\n",
    "\n",
    "# Define input and output data format\n",
    "input_data_format = 'text/plain'  # Adjust based on your model's expected input format\n",
    "output_data_format = 'application/jsonlines'  # Adjust based on your model's output format\n",
    "\n",
    "# Define S3 paths for input and output\n",
    "input_s3_path = 's3://textsagemaker/input-data/'  # Replace with the correct S3 path\n",
    "output_s3_path = 's3://outputbatchjobsagemaker/output-data/'  # Replace with the correct S3 path\n",
    "\n",
    "# Initialize a transformer object\n",
    "transformer = Transformer(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    strategy='SingleRecord'\n",
    ")\n",
    "\n",
    "# Start the batch transform job\n",
    "transformer.transform(\n",
    "    data=input_s3_path,\n",
    "    data_type='S3Prefix',\n",
    "    content_type=input_data_format,\n",
    "    split_type='Line',\n",
    "    input_filter='$[0,5]'\n",
    ")\n",
    "\n",
    "# Wait for the job to finish\n",
    "transformer.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84774ae5-2787-4c34-a755-2f19adec0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "def extract_consecutive_entities(file_path, threshold=0.8):\n",
    "    # Open the JSON lines file and extract consecutive entity types\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        consecutive_entities = {'PERSON': [], 'LOCATION': []}\n",
    "        current_entity_type = None\n",
    "        current_entity_score = None\n",
    "\n",
    "        for line in reader:\n",
    "            entities = line.get('entities', [])\n",
    "\n",
    "            for entity in entities:\n",
    "                entity_type = entity['type']\n",
    "                entity_score = entity['score']\n",
    "\n",
    "                if (\n",
    "                    current_entity_type == entity_type\n",
    "                    and current_entity_score > threshold\n",
    "                    and entity_score > threshold\n",
    "                ):\n",
    "                    # Consecutive entity with the same type and score above threshold\n",
    "                    consecutive_entities[entity_type].append(entity['text'])\n",
    "                else:\n",
    "                    # Start a new consecutive sequence\n",
    "                    consecutive_entities[entity_type] = [entity['text']]\n",
    "\n",
    "                current_entity_type = entity_type\n",
    "                current_entity_score = entity_score\n",
    "\n",
    "    return consecutive_entities\n",
    "\n",
    "def process_output_files(bucket, prefix):\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # List objects in the S3 bucket with the specified prefix\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "    # Process each output file\n",
    "    for obj in response.get('Contents', []):\n",
    "        file_path = f\"s3://{bucket}/{obj['Key']}\"\n",
    "        consecutive_entities = extract_consecutive_entities(file_path)\n",
    "\n",
    "        print(f\"Consecutive Entities extracted from {file_path}:\")\n",
    "        print(\"Person Names:\", consecutive_entities['PERSON'])\n",
    "        print(\"Locations:\", consecutive_entities['LOCATION'])\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Replace 'your-s3-bucket' and 'your-output-prefix' with your S3 bucket and output prefix\n",
    "process_output_files(bucket='your-s3-bucket', prefix='your-output-prefix')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
